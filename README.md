# Model Fine-Tuning on 7b Model with LoRa Integration

Note: Due to GPU limitations and memory issues, thorough testing and evaluation of the model's performance were not feasible.

I've studied and got help from the following two articles:

1) [Practical Tips for Finetuning LLMs Using LoRA (Low-Rank Adaptation)](https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms)
2) [Fine-Tuning Tutorial: Falcon-7b LLM To A General Purpose Chatbot](https://www.labellerr.com/blog/hands-on-with-fine-tuning-llm/)

## Objective: 
This project focuses on fine-tuning a large-scale pre-trained model with at least 7 billion parameters, incorporating LoRa (Long Range) technology for efficient and effective adaptation. This README details the process and outcomes of fine-tuning the Falcon-7b Large Language Model (LLM) using the QLoRA technique, focused on creating a mental health chatbot. 
